{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ledger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General preprocessing to go from ledger to artifact_code/\n",
    "\n",
    "Note that some of the artifacts may have separate preprocessing notebooks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy matplotlib seaborn scipy scikit-learn torch multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.data_loading_no_demo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING; takes ~1.5min\n",
    "ledger_len = pd.read_csv( 'data/ledger_len.csv', low_memory=False )\n",
    "\n",
    "# focus only on train\n",
    "sub_ledger = ledger_len[ ledger_len['split_full'].str.contains('train') ].reset_index(drop=True)\n",
    "sub_ledger.columns = [ c.lower() if c!='ID' else c for c in sub_ledger.columns ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate PVI and loss up to model-level (with other model-level metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [ 'score_var', 'model_name', 'ID', 'epoch' ]\n",
    "split_lst = ['train-None', 'train-Constant', 'val', 'test']\n",
    "comp_cols = [ 'boundary_prox', 'losses', 'pvi', 'times_forgotten', 'instance_hardness', 'irt_difficulty', 'tok_len' ]\n",
    "\n",
    "model_diff = sub_ledger.groupby( id_cols[:-1] )[ comp_cols ].mean().reset_index()\n",
    "model_diff['strat'] = [ s[-1] for s in model_diff['model_name'].str.split('-') ]\n",
    "\n",
    "model_diff.to_csv( 'artifact_code/data/model_diff.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_id_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used as a more efficient way to get the number of data observations by task and split\n",
    "# (rather than using the full ledger each time)\n",
    "dataset_id_counts = sub_ledger.groupby( ['score_var', 'split_full'] ).agg({ 'ID': 'nunique' }).reset_index().rename(\n",
    "    columns={'ID': 'n_unique_IDs'})\n",
    "\n",
    "dataset_id_counts.to_csv( 'artifact_code/data/dataset_id_counts.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_perform_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame is used to calculate all performance and fairness related metrics in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeracy\n",
      "Anxiety\n",
      "TrustPhys\n",
      "SubjectiveLit\n"
     ]
    }
   ],
   "source": [
    "from utils.post_processing import remove_duplicate_id\n",
    "\n",
    "# this object is used to ensure we don't lose any observations when performing joins\n",
    "check_counts = ledger_len.groupby([ 'score_var' ])[ 'ID' ].count().reset_index().rename(columns={'ID': 'count'})\n",
    "\n",
    "# this function joins demographic variables to the ledger and checks to ensure no data is added / lost\n",
    "def add_demos_to_ledger(this_ledger):\n",
    "    jdf_lst = []\n",
    "    for svar in this_ledger['score_var'].unique():\n",
    "        sdf = this_ledger[ this_ledger['score_var']==svar ]\n",
    "        print( svar )\n",
    "\n",
    "        # NOTE; Depression data with 'wer' (Word Error Rate) score variable not publicly available via IRB\n",
    "        if svar == 'wer':    \n",
    "            these_demos = pd.read_excel( 'data/data_zda/DenamedDemographics_and_more.xlsx' )\n",
    "            jdf = pd.merge( sdf, these_demos, how='left',\n",
    "                                        left_on='user', right_on='Subject.ID' )\n",
    "        else:\n",
    "            these_demos = load_and_process_demo('data/DataCVFolds/', svar)\n",
    "            id_text = pd.concat( load_hal_data('data/DataCVFolds/', svar, subset=False).values() )[['ID', 'text']].drop_duplicates()\n",
    "            sdf = pd.merge( sdf, id_text, on='ID', how='left' ) \n",
    "\n",
    "            # join demographic info\n",
    "            these_demos = load_and_process_demo('data/DataCVFolds/', svar)\n",
    "            these_demos = these_demos[these_demos['File']==1].reset_index(drop=True)\n",
    "\n",
    "            jdf = pd.merge(sdf, these_demos, left_on='text',\n",
    "                            right_on='Text_'+svar, how='left').drop('Text_'+svar, axis=1)\n",
    "        \n",
    "        # JOIN CHECK: must have the same number of IDs in the existing ledger for this task-split\n",
    "        join_check_num = check_counts[check_counts['score_var']==svar]['count'].iloc[0]\n",
    "        if join_check_num != len(jdf):\n",
    "            print('-----------------------------')\n",
    "            print(f'JOIN PROBLEM WITH {svar}')\n",
    "            print('-----------------------------')\n",
    "            raise ValueError('Shape of joined data must match expected dimensions of this_ledger')\n",
    "        \n",
    "        jdf_lst.append( jdf )\n",
    "\n",
    "    return pd.concat( jdf_lst )\n",
    "\n",
    "\n",
    "# WARNING; takes ~20sec\n",
    "full_ledger_len = add_demos_to_ledger(ledger_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# this function converts demographics columns to which rows fall into the protected vs. privileged\n",
    "# classes -- used for disparate impact (DI) calculations\n",
    "def add_prot_cols(tdf):\n",
    "    this_svar = tdf['score_var'].iloc[0]\n",
    "\n",
    "    # NOTE; Depression data with 'wer' (Word Error Rate) score variable not publicly available via IRB\n",
    "    if this_svar == 'wer':\n",
    "        tdf['Sex'] = np.where( tdf['Subject.Gender']!='Male', 2, 1 )\n",
    "        tdf['Age_Senior'] = np.where( tdf['Age_x'] >= 50, 1, 0 )     # 33 yrs old is median\n",
    "        tdf['Race_POC'] = np.where( tdf['Subject.Race']!='White/Caucasian', 1, 0 )\n",
    "        tdf['Education_Low'] = np.where( ((tdf['Subject.Education.Level']=='Less Than High School') | \n",
    "                                                (tdf['Subject.Education.Level']=='College or Trade or Vocational School')), 1, 0 )\n",
    "        # tdf['Income_Low'] = np.where( tdf['Income_Cat']<3, 1, 0 )\n",
    "        tdf['Income_Low'] = None      # not provided\n",
    "        tdf['ESL'] = 1        # all participants must speak English as first language\n",
    "\n",
    "    else:\n",
    "        # NOTE; no suffix on Age when we remove wer data\n",
    "        # tdf['Age_Senior'] = np.where( tdf['Age_y']>=65, 1, 0 )\n",
    "        tdf['Age_Senior'] = np.where( tdf['Age']>=65, 1, 0 )\n",
    "        tdf['Race_POC'] = np.where( tdf['Race']!=1, 1, 0 )\n",
    "        tdf['Education_Low'] = np.where( tdf['Education']<3, 1, 0 )\n",
    "        tdf['Income_Low'] = np.where( tdf['Income_Cat']<3, 1, 0 )\n",
    "        tdf['ESL'] = np.where( tdf['English_First_Lang']!=1, 1, 0 )\n",
    "\n",
    "    return tdf\n",
    "\n",
    "# this function calculates disparate impact with an alpha=0.05 smoothing value\n",
    "# (for when there are 0 people in the privileged class)\n",
    "def calculate_disp_impact(tdf, this_demo, alpha=0.005):\n",
    "    prot_df = tdf[tdf[this_demo]==1]\n",
    "    priv_df = tdf[tdf[this_demo]!=1]\n",
    "\n",
    "    return ( prot_df['preds'].mean() / (priv_df['preds'].mean()+alpha) )\n",
    "\n",
    "# this function calculates ADJUSTED disparate impact with an alpha=0.05 smoothing value\n",
    "# incorporates the base rate, but we report standard / unadjusted DI due to its legal\n",
    "# implications for 0.8 and 1.2 thresholds\n",
    "def calculate_adj_disp_impact(tdf, this_demo, alpha=0.05):\n",
    "    prot_df = tdf[tdf[this_demo]==1]\n",
    "    priv_df = tdf[tdf[this_demo]!=1]\n",
    "\n",
    "    p_prot = prot_df['preds'].mean()\n",
    "    base_prot = prot_df['labels'].mean()\n",
    "\n",
    "    p_priv = priv_df['preds'].mean()\n",
    "    base_priv = priv_df['labels'].mean()\n",
    "\n",
    "    return ( p_prot*base_priv) / ( ( p_priv*base_prot ) + alpha)\n",
    "\n",
    "\n",
    "# this function reads in logs (from trained models) and calculates the best\n",
    "# performance epoch (according to Val AUC)\n",
    "def create_perform_tdf(mn):\n",
    "    this_log = pd.read_csv( f'logs/{mn}_log.txt', sep='\\t' )\n",
    "    this_best_ep = this_log.loc[this_log['val_auc'].idxmax(), 'epoch']\n",
    "    tdf = full_ledger_len[( (full_ledger_len['model_name']==mn) &\n",
    "                    (full_ledger_len['epoch']==this_best_ep) &\n",
    "                     (full_ledger_len['split_full']=='test') )]\n",
    "    tdf['best_epoch'] = this_best_ep\n",
    "    return tdf\n",
    "\n",
    "\n",
    "# this function calculates performance metrics from the best epoch of each model\n",
    "# and adds fairness metrics\n",
    "def proc_test_perform_row(tdf):\n",
    "    tdf_full = add_prot_cols(tdf)\n",
    "\n",
    "    this_acc = tdf_full['correct'].mean()\n",
    "    this_auc = roc_auc_score( y_true=tdf_full['labels'], y_score=tdf_full['probs'] )\n",
    "    this_f1 = f1_score( y_true=tdf_full['labels'], y_pred=tdf_full['preds'] )\n",
    "\n",
    "    new_row = pd.DataFrame.from_dict( [{\n",
    "        'model_name': tdf_full['model_name'].iloc[0], 'test_acc': this_acc,\n",
    "        'test_auc': this_auc, 'test_f1': this_f1,\n",
    "        'best_epoch': tdf_full['best_epoch'].iloc[0]\n",
    "    }] )\n",
    "\n",
    "    these_demos = ['Sex', 'Age_Senior', 'Race_POC', 'Education_Low', 'Income_Low', 'ESL']\n",
    "    for this_demo in these_demos:\n",
    "        new_row[this_demo+\"|DI\"] = calculate_disp_impact(tdf_full, this_demo)\n",
    "        new_row[this_demo+\"|ADI\"] = calculate_adj_disp_impact(tdf_full, this_demo)\n",
    "\n",
    "    return new_row\n",
    "\n",
    "\n",
    "# simplify model names for easier reading\n",
    "mt_d = {\n",
    "    'bert-base-uncased': 'bert',\n",
    "    'xlm-roberta-base-uncased-all-english': 'roberta',\n",
    "    'local-ffn': 'ffn',\n",
    "    'local-cnn': 'cnn',\n",
    "    'local-lstm': 'lstm'\n",
    "}\n",
    "\n",
    "these_mns = list( sub_ledger['model_name'].unique() )\n",
    "\n",
    "\n",
    "# NOTE; parallelization supported on Linux but won't work on Windows\n",
    "# import multiprocess\n",
    "# #multisetup\n",
    "# cores_to_use = multiprocess.cpu_count()-1\n",
    "# pool = multiprocess.Pool(cores_to_use)\n",
    "\n",
    "# # multi create\n",
    "# # WARNING; takes ~1min\n",
    "# with multiprocess.Pool(cores_to_use) as pool:\n",
    "#     tdf_lst = pool.map(create_perform_tdf, these_mns)\n",
    "\n",
    "# # multi proc\n",
    "# with multiprocess.Pool(cores_to_use) as pool:\n",
    "#     perform_lst = pool.map(proc_test_perform_row, tdf_lst)\n",
    "\n",
    "\n",
    "# serial application of the above functions (works on any OS)\n",
    "# WARNING; takes ~3min\n",
    "tdf_lst = [ create_perform_tdf(mn) for mn in these_mns ]\n",
    "perform_lst = [ proc_test_perform_row(tdf) for tdf in tdf_lst ]\n",
    "\n",
    "test_perform_df = pd.concat( perform_lst ).reset_index(drop=True)\n",
    "\n",
    "# add task, hard vs. random split, and type of model (all contained in model names)\n",
    "test_perform_df['score_var'] = [ s.split('_')[1] for s in test_perform_df['model_name'] ]\n",
    "test_perform_df['strat'] = [ s.split('_')[-1].split('-')[1] for s in test_perform_df['model_name'] ]\n",
    "test_perform_df['model_type'] = [ mt_d[ s[0] ] for s in test_perform_df['model_name'].str.split('_') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ability from the py-irt response patterns\n",
    "all_ab_df = pd.DataFrame()\n",
    "for svar in test_perform_df['score_var'].unique():\n",
    "    ab_df = pd.read_csv( f\"py-irt_response-patterns/{svar}_test_mn_ability.csv\" )\n",
    "    all_ab_df = pd.concat([ all_ab_df, ab_df ])\n",
    "\n",
    "\n",
    "# merge and clean the final dataframe for results and fairness\n",
    "test_perform_full = pd.merge( test_perform_df, all_ab_df, on='model_name', how='left' )\n",
    "\n",
    "id_cols = ['model_name', 'model_type', 'score_var', 'strat', 'best_epoch']\n",
    "perform_cols = [ 'test_acc', 'test_auc', 'test_f1', 'irt_ability' ]\n",
    "di_cols = [ c for c in test_perform_full if '|DI' in c ]\n",
    "adi_cols = [ c for c in test_perform_full if '|ADI' in c ]\n",
    "test_perform_full = test_perform_full[id_cols+perform_cols+di_cols+adi_cols]\n",
    "\n",
    "test_perform_full.to_csv( 'artifact_code/data/test_perform_full.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muadib2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
