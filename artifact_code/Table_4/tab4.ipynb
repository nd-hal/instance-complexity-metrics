{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **/kld_demos/ data not able to be included due privacy concerns so code will not execute successfully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "#dictionaries used to rename outputs for readabaility\n",
    "comp_d = {\n",
    "    'boundary_dist': 'BD',\n",
    "    'times_forgotten': 'TF',\n",
    "    'instance_hardness': 'IH',\n",
    "    'losses': 'Loss',\n",
    "    'irt_difficulty': 'IRT',\n",
    "    'tok_len': 'SL',\n",
    "    'pvi': 'PVI'\n",
    "}\n",
    "\n",
    "demo_d = {\n",
    "    'Age_Senior': 'Age',\n",
    "    'Race_POC': 'Race',\n",
    "    'Education_Low': 'Educ.',\n",
    "    'Sex': 'Sex',\n",
    "    'Income_Low': 'Inc.',\n",
    "    'ESL': 'ESL'\n",
    "}\n",
    "\n",
    "demo_order = ['Age', 'Sex', 'Race', 'Educ.', 'Inc.', 'ESL']\n",
    "\n",
    "svar_d = {\n",
    "    'Anxiety': 'Anxiety',\n",
    "    'Numeracy': 'Numeracy',\n",
    "    'SubjectiveLit': 'Literacy',\n",
    "    'TrustPhys': 'Trust',\n",
    "    'wer': 'Depr.'\n",
    "}\n",
    "\n",
    "svar_order = ['Anxiety', 'Numeracy', 'Literacy', 'Trust', 'Depr.']\n",
    "\n",
    "\n",
    "# this function calculates the KLD divergence between the distributions of protected and privileged\n",
    "# classes for a given complexity metric -- larger values indicate fairness violations\n",
    "# in Lorena et al. (2024)\n",
    "def calculate_vec_kld(df, demo_met, comp_met, prot_class, alpha=0.005):\n",
    "    prot_vals = df[df[demo_met]==prot_class][comp_met]\n",
    "    maj_vals = df[df[demo_met]!=prot_class][comp_met]\n",
    "\n",
    "    # bin into probability distributions\n",
    "    these_bins = np.arange( min(df[comp_met]), max(df[comp_met]), step=df[comp_met].std()/10 )\n",
    "    this_P = pd.Series( pd.cut(prot_vals, bins=these_bins).value_counts(normalize=True), name='prot' )\n",
    "    this_Q = pd.Series( pd.cut(maj_vals, bins=these_bins).value_counts(normalize=True), name='maj' )\n",
    "\n",
    "    # concatenate and smooth slightly\n",
    "    pdf = pd.concat([this_P, this_Q], axis=1).reset_index()\n",
    "    pdf['maj'] += alpha\n",
    "    pdf['prot'] += alpha\n",
    "\n",
    "    this_kld = sum( pdf['prot'] * ( np.log( pdf['prot'] / pdf['maj'] ) ) )\n",
    "    return this_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicates values of the protected class for each demo\n",
    "protected_d = {\n",
    "    'Sex': 2,\n",
    "    'Age_Senior': 1,\n",
    "    'Race_POC': 1,\n",
    "    'Education_Low': 1,\n",
    "    'Income_Low': 1,\n",
    "    'ESL': 1\n",
    "}\n",
    "\n",
    "these_svars = [ 'Anxiety', 'Numeracy', 'SubjectiveLit', 'TrustPhys', 'wer' ]\n",
    "comp_cols = [ 'boundary_dist', 'losses', 'pvi', 'times_forgotten', 'instance_hardness', 'irt_difficulty', 'tok_len' ]\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "os.chdir('..')\n",
    "model_diff = pd.read_csv( 'data/model_diff.csv' )\n",
    "model_diff['strat'] = [ s[-1] for s in model_diff['model_name'].str.split('-') ]\n",
    "\n",
    "sv_diff = model_diff.groupby( ['score_var', 'ID'] )[ comp_cols ].mean()\n",
    "\n",
    "\n",
    "\n",
    "# NOTE; demographic files not provided -- please reach out to the authors for data\n",
    "kl_df = pd.DataFrame()\n",
    "for svar in these_svars:\n",
    "\n",
    "    subset = False\n",
    "\n",
    "    # NOTE; converted to data checkpoint to maintain data privacy\n",
    "    # if svar == 'wer':\n",
    "    #     # print('using ZDA data')\n",
    "    #     input_data_d = load_zda_data('data/data_zda/', subset=subset)\n",
    "    # elif svar == 'drug':\n",
    "    #     # print('using DRUG data')\n",
    "    #     input_data_d = load_drug_data('data/', subset=subset)\n",
    "    # else:\n",
    "    #     # print('using HAL data')\n",
    "    #     input_data_d = load_hal_data('data/DataCVFolds/', score_variable=svar, subset=subset)\n",
    "\n",
    "    # # create hard, random subsets\n",
    "    # input_data_d['hard_train_data'], input_data_d['rand_train_data'] = sample_hard_rand(input_data_d['train_data'], svar)\n",
    "\n",
    "    # # join the complexity metrics\n",
    "    # input_data_d['hard_train_data']['score_var'] = svar\n",
    "    # input_data_d['rand_train_data']['score_var'] = svar\n",
    "\n",
    "    # hard_join = pd.merge( input_data_d['hard_train_data'], sv_diff, on=['score_var', 'ID'], how='inner' )\n",
    "    # rand_join = pd.merge( input_data_d['rand_train_data'], sv_diff, on=['score_var', 'ID'], how='inner' )\n",
    "\n",
    "    # full_join = pd.concat([ hard_join, rand_join ])\n",
    "\n",
    "\n",
    "    # full_join.to_csv( f'artifact_code/data/kld_demos/full_join-for{svar}.csv', index=False )\n",
    "\n",
    "    full_join = pd.read_csv( f'data/kld_demos/full_join-for{svar}.csv' )\n",
    "    \n",
    "    # create protected class indicator vars\n",
    "    if svar == 'wer':\n",
    "        full_join['Sex'] = np.where( full_join['Subject.Gender']!='Male', 2, 1 )\n",
    "        full_join['Age_Senior'] = np.where( (full_join['Age'].astype(float) >=\n",
    "                                             full_join['Age'].astype(float).median()), 1, 0 )\n",
    "        full_join['Race_POC'] = np.where( full_join['Subject.Race']!='White/Caucasian', 1, 0 )\n",
    "        full_join['Education_Low'] = np.where( ((full_join['Subject.Education.Level']=='Less Than High School') | \n",
    "                                                (full_join['Subject.Education.Level']=='College or Trade or Vocational School')), 1, 0 )\n",
    "        # full_join['Income_Low'] = np.where( full_join['Income_Cat']<3, 1, 0 )\n",
    "        full_join['Income_Low'] = None      # not provided\n",
    "        full_join['ESL'] = 1        # all participants must speak English as first language\n",
    "\n",
    "    else:\n",
    "        full_join['Age_Senior'] = np.where( full_join['Age']>=65, 1, 0 )\n",
    "        full_join['Race_POC'] = np.where( full_join['Race']!=1, 1, 0 )\n",
    "        full_join['Education_Low'] = np.where( full_join['Education']<3, 1, 0 )\n",
    "        full_join['Income_Low'] = np.where( full_join['Income_Cat']<3, 1, 0 )\n",
    "        full_join['ESL'] = np.where( full_join['English_First_Lang']!=1, 1, 0 )\n",
    "\n",
    "    \n",
    "    for demo_met, prot_class in protected_d.items():\n",
    "        for comp_met in comp_cols:\n",
    "            this_kl = calculate_vec_kld(full_join, demo_met, comp_met, prot_class)\n",
    "\n",
    "            new_row = pd.DataFrame.from_dict([{\n",
    "                'score_var': svar_d[svar], 'demo_met': demo_met,\n",
    "                'comp_met': comp_met, 'KLD': this_kl\n",
    "                }])\n",
    "            kl_df = pd.concat([ kl_df, new_row])\n",
    "\n",
    "kl_df = kl_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "os.chdir(this_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "odf = kl_df.pivot_table(index=['score_var', 'comp_met'], columns='demo_met', values='KLD')\n",
    "odf = odf.fillna('-')\n",
    "\n",
    "\n",
    "for c in demo_d.keys():\n",
    "    # odf[c] = [ '\\\\textbf{' + f'{v:.2f}' +'}' if v>=2 else f'{v:.2f}' for v in odf[c] ]\n",
    "    odf[c] = [ f'{v:.2f}' if type(v)==float else v for v in odf[c] ]\n",
    "\n",
    "odf.columns = [ demo_d[c] for c in odf.columns ]\n",
    "odf.index.names = [None, None]\n",
    "# convert to print names and add colors\n",
    "odf.index = pd.MultiIndex.from_tuples([ (t[0], comp_d[t[1]]) for t in odf.index ])\n",
    "odf.index = pd.MultiIndex.from_tuples( [ (t[0], ( '\\\\red{' + t[1] +'}' if t[1] in ['BD', 'PVI'] else \n",
    "                                                 '\\\\blue{' + t[1] +'}' ) ) for t in odf.index ] )\n",
    "\n",
    "odf = odf.loc[svar_order][demo_order]\n",
    "odf.to_latex( 'demo_comp_v5.tex' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muadib2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
