{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_cols = [ 'boundary_dist', 'losses', 'pvi', 'times_forgotten', 'instance_hardness', 'irt_difficulty', 'tok_len' ]\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "os.chdir('..')\n",
    "# NOTE; Depression data with 'wer' (Word Error Rate) score variable not publicly available via IRB\n",
    "# both data files can be generated from ArtifactPreprocessing.ipynb\n",
    "id_counts = pd.read_csv( 'data/dataset_id_counts.csv' )\n",
    "model_diff = pd.read_csv( 'data/model_diff.csv' )\n",
    "# bug where 'None' strategy (i.e., a string) loaded as None/NaN\n",
    "model_diff['strat'] = model_diff['strat'].fillna('None')\n",
    "\n",
    "os.chdir(this_dir)\n",
    "\n",
    "# this function groups by task and strategy (i.e., Hard or Random split) and adds CIs\n",
    "def create_join_gdf( in_df, id_counts ):\n",
    "    full_gdf = in_df.groupby(['score_var', 'strat'])[ comp_cols ].agg(['mean', 'var'])\n",
    "    full_gdf.columns = [ '_'.join([c1, c2]) for c1, c2 in zip( full_gdf.columns.get_level_values(0),\n",
    "                                                                full_gdf.columns.get_level_values(1) ) ]\n",
    "\n",
    "    # need to consider N from the number of original data points / sources of variation\n",
    "    # NOTE; we do this in \"id_counts\" since \"sub_ledger\" is too large\n",
    "    # id_counts = sub_ledger.groupby(['score_var', 'split_full'])[['ID']].nunique().rename(\n",
    "    #     columns={'ID': 'n_unique_IDs'}).reset_index()\n",
    "\n",
    "    id_counts['strat'] = [ s.split('-')[-1] for s in id_counts['split_full'] ]\n",
    "    id_counts = id_counts.drop('split_full', axis=1)\n",
    "\n",
    "    join_gdf = pd.merge( full_gdf, id_counts, how='left', on=['score_var', 'strat'] )\n",
    "    join_gdf = join_gdf.set_index(['score_var', 'strat'])\n",
    "\n",
    "\n",
    "    # add confidence intervals according to these Ns\n",
    "    z = 1.96\n",
    "    for c in comp_cols:\n",
    "        \n",
    "        this_sem = (join_gdf[c+'_var'])**0.5 / np.sqrt(join_gdf['n_unique_IDs'])\n",
    "        # join_gdf[c+'_zscore'] = this_zscore\n",
    "\n",
    "        join_gdf[c+'_cilow'] = join_gdf[c+'_mean'] - z*this_sem\n",
    "        join_gdf[c+'_cihigh'] = join_gdf[c+'_mean'] + z*this_sem\n",
    "\n",
    "    return join_gdf\n",
    "\n",
    "\n",
    "join_gdf_wer = create_join_gdf( model_diff, id_counts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates a z-score from pooled variance (across Hard and Random\n",
    "# strategies)\n",
    "def calculate_zscore(rand_row, hard_row, met):\n",
    "    z = 1.96\n",
    "\n",
    "    rand_mean, rand_var = rand_row[met+'_mean'], rand_row[met+'_var']\n",
    "    hard_mean, hard_var = hard_row[met+'_mean'], hard_row[met+'_var']\n",
    "\n",
    "    n_rand, n_hard = rand_row['n_unique_IDs'], hard_row['n_unique_IDs']\n",
    "    pooled_var = ( ((n_rand-1)*rand_var) + ((n_hard-1)*hard_var) ) / ( n_rand+n_hard-2 )\n",
    "    pooled_sem = ( (pooled_var/n_rand) + (pooled_var/n_hard) )**0.5\n",
    "\n",
    "    # expect rand sample to have higher inv metrics\n",
    "    if met in [ 'boundary_prox', 'pvi' ]:\n",
    "        this_zscore = (rand_mean - hard_mean) / pooled_sem\n",
    "    # ...hard sample to have higher prop metrics\n",
    "    else:\n",
    "        this_zscore = (hard_mean - rand_mean) / pooled_sem\n",
    "\n",
    "    return this_zscore\n",
    "\n",
    "\n",
    "# NOTE; Depression data with 'wer' (Word Error Rate) score variable not publicly available via IRB\n",
    "# renaming for readability\n",
    "sv_d = {\n",
    "    'Anxiety': 'Anxiety',\n",
    "    'Numeracy': 'Numeracy',\n",
    "    'SubjectiveLit': 'Literacy',\n",
    "    'TrustPhys': 'Trust',\n",
    "    # 'wer': 'Depr.'\n",
    "    }\n",
    "\n",
    "ic_d = {\n",
    "    'boundary_dist': 'BD',\n",
    "    'losses': 'Loss',\n",
    "    'times_forgotten': 'TF',\n",
    "    'irt_difficulty': 'IRT',\n",
    "    'instance_hardness': 'IH',\n",
    "    'pvi': 'PVI',\n",
    "    'tok_len': 'SL'\n",
    "}\n",
    "\n",
    "\n",
    "# this function creates Table 2 in the paper used to compare difference\n",
    "# in sampling strategy for each complexity metric\n",
    "def create_table2(this_join_gdf):\n",
    "    mean_diff_df = pd.DataFrame()\n",
    "\n",
    "    these_svars = np.unique( [ t[0] for t in this_join_gdf.index ] )\n",
    "\n",
    "    for svar in these_svars:\n",
    "\n",
    "        rand_row = this_join_gdf.loc[(svar, 'None'), :]\n",
    "        hard_row = this_join_gdf.loc[(svar, 'Constant'), :]\n",
    "\n",
    "        sub_df = pd.DataFrame()\n",
    "        for met in comp_cols:\n",
    "            rand_mean, rand_std = rand_row[met+'_mean'], rand_row[met+'_var']**.05\n",
    "            hard_mean, hard_std = hard_row[met+'_mean'], hard_row[met+'_var']**0.5\n",
    "\n",
    "            # note we consider the random sample to be \"true\"\n",
    "            this_zscore = calculate_zscore(rand_row, hard_row, met)\n",
    "            # print(svar, met)\n",
    "\n",
    "            total_prob = scipy.stats.norm.cdf(-this_zscore)  # one-sided\n",
    "\n",
    "            # apply bonferroni correction\n",
    "            this_sig = '*' if total_prob < 0.05/len(ic_d) else ''\n",
    "\n",
    "            pool_std = ((hard_std**2) + (rand_std**2) / 2)**0.5\n",
    "            new_row = pd.DataFrame.from_dict([{\n",
    "                'Dep. Var.': sv_d[svar], 'Metric': ic_d[met],\n",
    "                'Mean Diff.': f'{hard_mean-rand_mean:.3f}{this_sig}',\n",
    "                'Pool. SD': f'{pool_std:.3f}',\n",
    "                # 'p<0.05': f'{total_prob:.4f}{this_sig}'\n",
    "            }])\n",
    "\n",
    "            sub_df = pd.concat([sub_df, new_row])\n",
    "\n",
    "\n",
    "        mean_diff_df = pd.concat([ mean_diff_df, sub_df ])\n",
    "\n",
    "    mean_diff_df = mean_diff_df.reset_index(drop=True)\n",
    "\n",
    "    mean_diff_df = mean_diff_df.set_index(['Dep. Var.', 'Metric'])\n",
    "    mean_diff_df.index.names = [ None, None ]\n",
    "    mean_diff_df.index = pd.MultiIndex.from_tuples( [ (t[0], ( '\\\\red{' + t[1] +'}' if t[1] in ['BD', 'PVI'] else \n",
    "                                                            '\\\\blue{' + t[1] +'}' ) ) for t in mean_diff_df.index ] )\n",
    "    \n",
    "    mean_diff_df = mean_diff_df[['Mean Diff.']].unstack(level=-1).T\n",
    "    mean_diff_df.index = [ t[1] for t in mean_diff_df.index ]\n",
    "    return mean_diff_df\n",
    "\n",
    "\n",
    "# run the function\n",
    "table_wer = create_table2(join_gdf_wer)\n",
    "\n",
    "# NOTE; Depression data with 'wer' (Word Error Rate) score variable not publicly available via IRB\n",
    "table_wer.to_latex( 'comp_mean_diff_inc_wer.tex' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muadib2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
