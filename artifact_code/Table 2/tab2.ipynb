{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_cols = [ 'boundary_prox', 'losses', 'pvi', 'times_forgotten', 'instance_hardness', 'irt_difficulty', 'tok_len' ]\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "os.chdir('..')\n",
    "id_counts = pd.read_csv( 'data/dataset_id_counts.csv' )\n",
    "model_diff = pd.read_csv( 'data/model_diff.csv' )\n",
    "# bug where 'None' strategy (i.e., a string) loaded as None/NaN\n",
    "model_diff['strat'] = model_diff['strat'].fillna('None')\n",
    "\n",
    "os.chdir(this_dir)\n",
    "\n",
    "def create_join_gdf( in_df, id_counts ):\n",
    "    full_gdf = in_df.groupby(['score_var', 'strat'])[ comp_cols ].agg(['mean', 'var'])\n",
    "    full_gdf.columns = [ '_'.join([c1, c2]) for c1, c2 in zip( full_gdf.columns.get_level_values(0),\n",
    "                                                                full_gdf.columns.get_level_values(1) ) ]\n",
    "\n",
    "    # need to consider N from the number of original data points / sources of variation\n",
    "    # NOTE; we do this in \"id_counts\" since \"sub_ledger\" is too large\n",
    "    # id_counts = sub_ledger.groupby(['score_var', 'split_full'])[['ID']].nunique().rename(\n",
    "    #     columns={'ID': 'n_unique_IDs'}).reset_index()\n",
    "\n",
    "\n",
    "    id_counts['strat'] = [ s.split('-')[-1] for s in id_counts['split_full'] ]\n",
    "    id_counts = id_counts.drop('split_full', axis=1)\n",
    "\n",
    "    join_gdf = pd.merge( full_gdf, id_counts, how='left', on=['score_var', 'strat'] )\n",
    "    join_gdf = join_gdf.set_index(['score_var', 'strat'])\n",
    "\n",
    "\n",
    "    # add confidence intervals according to these Ns\n",
    "    z = 1.96\n",
    "    for c in comp_cols:\n",
    "        \n",
    "        this_sem = (join_gdf[c+'_var'])**0.5 / np.sqrt(join_gdf['n_unique_IDs'])\n",
    "        # join_gdf[c+'_zscore'] = this_zscore\n",
    "\n",
    "        join_gdf[c+'_cilow'] = join_gdf[c+'_mean'] - z*this_sem\n",
    "        join_gdf[c+'_cihigh'] = join_gdf[c+'_mean'] + z*this_sem\n",
    "\n",
    "    return join_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_gdf_wer = create_join_gdf( model_diff, id_counts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscore(rand_row, hard_row, met):\n",
    "    z = 1.96\n",
    "\n",
    "    rand_mean, rand_var = rand_row[met+'_mean'], rand_row[met+'_var']\n",
    "    hard_mean, hard_var = hard_row[met+'_mean'], hard_row[met+'_var']\n",
    "\n",
    "    n_rand, n_hard = rand_row['n_unique_IDs'], hard_row['n_unique_IDs']\n",
    "    pooled_var = ( ((n_rand-1)*rand_var) + ((n_hard-1)*hard_var) ) / ( n_rand+n_hard-2 )\n",
    "    pooled_sem = ( (pooled_var/n_rand) + (pooled_var/n_hard) )**0.5\n",
    "\n",
    "    # expect rand sample to have higher inv metrics\n",
    "    if met in [ 'boundary_prox', 'pvi' ]:\n",
    "        this_zscore = (rand_mean - hard_mean) / pooled_sem\n",
    "    # ...hard sample to have higher prop metrics\n",
    "    else:\n",
    "        this_zscore = (hard_mean - rand_mean) / pooled_sem\n",
    "\n",
    "    return this_zscore\n",
    "\n",
    "\n",
    "\n",
    "sv_d = {\n",
    "    'Anxiety': 'Anxiety',\n",
    "    'Numeracy': 'Numeracy',\n",
    "    'SubjectiveLit': 'Literacy',\n",
    "    'TrustPhys': 'Trust',\n",
    "    'wer': 'Depr.'\n",
    "    }\n",
    "\n",
    "ic_d = {\n",
    "    'boundary_prox': 'BP',\n",
    "    'losses': 'Loss',\n",
    "    'times_forgotten': 'TF',\n",
    "    'irt_difficulty': 'IRT',\n",
    "    'instance_hardness': 'IH',\n",
    "    'pvi': 'PVI',\n",
    "    'tok_len': 'SL'\n",
    "}\n",
    "\n",
    "\n",
    "def create_table2(this_join_gdf):\n",
    "    mean_diff_df = pd.DataFrame()\n",
    "\n",
    "    these_svars = np.unique( [ t[0] for t in this_join_gdf.index ] )\n",
    "\n",
    "    for svar in these_svars:\n",
    "\n",
    "        rand_row = this_join_gdf.loc[(svar, 'None'), :]\n",
    "        hard_row = this_join_gdf.loc[(svar, 'Constant'), :]\n",
    "\n",
    "        sub_df = pd.DataFrame()\n",
    "        for met in comp_cols:\n",
    "            rand_mean, rand_std = rand_row[met+'_mean'], rand_row[met+'_var']**.05\n",
    "            hard_mean, hard_std = hard_row[met+'_mean'], hard_row[met+'_var']**0.5\n",
    "\n",
    "            # note we consider the random sample to be \"true\"\n",
    "            this_zscore = calculate_zscore(rand_row, hard_row, met)\n",
    "            # print(svar, met)\n",
    "\n",
    "            total_prob = scipy.stats.norm.cdf(-this_zscore)  # one-sided\n",
    "\n",
    "            # apply bonferroni correction\n",
    "            this_sig = '*' if total_prob < 0.05/len(ic_d) else ''\n",
    "\n",
    "            pool_std = ((hard_std**2) + (rand_std**2) / 2)**0.5\n",
    "            new_row = pd.DataFrame.from_dict([{\n",
    "                'Dep. Var.': sv_d[svar], 'Metric': ic_d[met],\n",
    "                'Mean Diff.': f'{hard_mean-rand_mean:.3f}{this_sig}',\n",
    "                'Pool. SD': f'{pool_std:.3f}',\n",
    "                # 'p<0.05': f'{total_prob:.4f}{this_sig}'\n",
    "            }])\n",
    "\n",
    "            sub_df = pd.concat([sub_df, new_row])\n",
    "\n",
    "\n",
    "        mean_diff_df = pd.concat([ mean_diff_df, sub_df ])\n",
    "\n",
    "    mean_diff_df = mean_diff_df.reset_index(drop=True)\n",
    "\n",
    "    mean_diff_df = mean_diff_df.set_index(['Dep. Var.', 'Metric'])\n",
    "    mean_diff_df.index.names = [ None, None ]\n",
    "    mean_diff_df.index = pd.MultiIndex.from_tuples( [ (t[0], ( '\\\\red{' + t[1] +'}' if t[1] in ['BP', 'PVI'] else \n",
    "                                                            '\\\\blue{' + t[1] +'}' ) ) for t in mean_diff_df.index ] )\n",
    "    \n",
    "    mean_diff_df = mean_diff_df[['Mean Diff.']].unstack(level=-1).T\n",
    "    mean_diff_df.index = [ t[1] for t in mean_diff_df.index ]\n",
    "    return mean_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_wer = create_table2(join_gdf_wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>Numeracy</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Depr.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\blue{IH}</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034*</td>\n",
       "      <td>0.032*</td>\n",
       "      <td>0.083*</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\blue{IRT}</th>\n",
       "      <td>0.043</td>\n",
       "      <td>1.200*</td>\n",
       "      <td>0.530</td>\n",
       "      <td>1.577*</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\blue{Loss}</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.063*</td>\n",
       "      <td>0.027*</td>\n",
       "      <td>0.093*</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\blue{SL}</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.907</td>\n",
       "      <td>-2.187</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\blue{TF}</th>\n",
       "      <td>0.159*</td>\n",
       "      <td>0.599*</td>\n",
       "      <td>0.361*</td>\n",
       "      <td>0.688*</td>\n",
       "      <td>0.409*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\red{BP}</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.051*</td>\n",
       "      <td>-0.103*</td>\n",
       "      <td>-0.101*</td>\n",
       "      <td>-0.033*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\red{PVI}</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Anxiety Literacy Numeracy    Trust    Depr.\n",
       "\\blue{IH}     0.000   0.034*   0.032*   0.083*    0.000\n",
       "\\blue{IRT}    0.043   1.200*    0.530   1.577*    0.358\n",
       "\\blue{Loss}   0.001   0.063*   0.027*   0.093*    0.006\n",
       "\\blue{SL}     0.996    0.867    0.907   -2.187    0.795\n",
       "\\blue{TF}    0.159*   0.599*   0.361*   0.688*   0.409*\n",
       "\\red{BP}     -0.004  -0.051*  -0.103*  -0.101*  -0.033*\n",
       "\\red{PVI}     0.022    0.087    0.104    0.153   -0.007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_wer[ ['Anxiety', 'Literacy', 'Numeracy', 'Trust', 'Depr.'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_wer.to_latex( 'comp_mean_diff_inc_wer.tex' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muadib2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
