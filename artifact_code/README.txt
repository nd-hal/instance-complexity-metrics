Any artifact (i.e., table or figure) in the paper that requires computation from raw data is included in this repository.  We note that some artifacts require preprocessing in Python (which was used for training / storing values) as well as a R script for plotting in ggplot.  

There are also several data checkpoints included in the /data/ folder.  All metrics are derived from a "ledger" of instance-level outputs and or performance logs of epoch-level model performance, which is omitted due to its difficult size (4.44 GB) and inclusion of proprietary depression task data.  Note that replication code is included for Table 4, but it will not run since the data does not meet privacy standards and is therefore excluded.









